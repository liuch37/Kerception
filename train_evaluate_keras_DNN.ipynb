{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code is to test Alexnet/VGG16 deep CNN networks on imagenet dataset, with and without kerception/kervolution.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tf_keras_kervolution_2d import KernelConv2D      # Kervolution\n",
    "from tf_keras_kervolution_2d import LinearKernel      # Equivalent to normal convolution\n",
    "from tf_keras_kervolution_2d import L1Kernel          # Manhattan distance\n",
    "from tf_keras_kervolution_2d import L2Kernel          # Euclidean distance\n",
    "from tf_keras_kervolution_2d import PolynomialKernel  # Polynomial\n",
    "from tf_keras_kervolution_2d import GaussianKernel    # Gaussin / RBF\n",
    "from tf_keras_kervolution_2d import SigmoidKernel     # Sigmoid\n",
    "from models.Alexnet import Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commands needed for GPU program\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
    "epochs = 200\n",
    "data_augmentation = False\n",
    "num_classes = 10\n",
    "# Model version\n",
    "# version = 1 (Alexnet), version = 2 (VGG16)\n",
    "version = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "(x_train, y_train), (x_test, y_test) = #Imagenet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('y_train shape:',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kerception_blockC(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Customized kervolution 2D + ratio proportional [0.1, 0.1, 0.2, 0.3, 0.3] inception block with total 16 filters.\n",
    "    Scheduling algorithm: allocation = floor(total_filters*ratio) -> remainder = total_filters - sum(allocation) -> Do allocation[-index]++ and remainder-- and index++ while remainder >= 0.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Kerception_blockC,self).__init__()\n",
    "        self.kernel_fn1 = LinearKernel()\n",
    "        self.kconv1 = KernelConv2D(filters=1, kernel_size=3, padding='same', kernel_function=self.kernel_fn1)\n",
    "        self.kernel_fn2 = SigmoidKernel()\n",
    "        self.kconv2 = KernelConv2D(filters=3, kernel_size=3, padding='same', kernel_function=self.kernel_fn2)\n",
    "        self.kernel_fn3 = GaussianKernel(gamma=1.0, trainable_gamma=True, initializer='he_normal')\n",
    "        self.kconv3 = KernelConv2D(filters=3, kernel_size=3, padding='same', kernel_function=self.kernel_fn3)\n",
    "        self.kernel_fn4 = PolynomialKernel(p=3, trainable_c=True, initializer='he_normal')\n",
    "        self.kconv4 = KernelConv2D(filters=6, kernel_size=3, padding='same', kernel_function=self.kernel_fn4)\n",
    "        self.kernel_fn5 = PolynomialKernel(p=5, trainable_c=True, initializer='he_normal')\n",
    "        self.kconv5 = KernelConv2D(filters=3, kernel_size=3, padding='same', kernel_function=self.kernel_fn5)\n",
    "\n",
    "    def call(self, x):\n",
    "        x1 = self.kconv1(x)\n",
    "        x2 = self.kconv2(x)\n",
    "        x3 = self.kconv3(x)\n",
    "        x4 = self.kconv4(x)\n",
    "        x5 = self.kconv5(x)\n",
    "\n",
    "        return tf.keras.layers.concatenate([x1, x2, x3, x4, x5], axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_scheduling(num_filters):\n",
    "    '''\n",
    "    This function is to return a list of number of filters for each kernel functions in Kerception block.\n",
    "    Input: \n",
    "    num_filters: total number of filters.\n",
    "    Output:\n",
    "    filter_num: Number of filters for each kernel function.\n",
    "    '''\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version == 1:\n",
    "    model = Alexnet(input_shape=(224,224,3), output_shape=num_classes)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=lr_schedule(0)),\n",
    "              metrics=['accuracy',tf.keras.metrics.SparseTopKCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [lr_reducer, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results:\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2, markersize=8)\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2, markersize=8)\n",
    "plt.title('Imagenet')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "plt.plot(history.history['sparse_top_k_categorical_accuracy'], label='Training Top-5 Accuracy', linewidth=2, markersize=8)\n",
    "plt.plot(history.history['val_sparse_top_k_categorical_accuracy'], label='Validation Top-5 Accuracy', linewidth=2, markersize=8)\n",
    "plt.title('Imagenet')\n",
    "plt.ylabel('Top-5 Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best validation top-1 accuracy is:{}\".format(max(history.history['val_accuracy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best validation top-5 accuracy is:{}\".format(max(history.history['val_sparse_top_k_categorical_accuracy'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
